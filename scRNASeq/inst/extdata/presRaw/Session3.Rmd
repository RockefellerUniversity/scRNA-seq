---
title: "Single-cell RNA sequencing ~ Session 2<html><div style='float:left'></div><hr color='#EB811B' size=1px width=796px></html>"
author: "Rockefeller University, Bioinformatics Resource Centre"
date: "http://rockefelleruniversity.github.io/scRNA-seq/"
output: 
  xaringan::moon_reader:
    css: ["default", "metropolisCustom.css", "metropolis-fontsCustom.css"]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
  html_document:
    toc: true # table of content true
    toc_float: yes
    depth: 3  # upto three depths of headings (specified by #, ## and ###)
    number_sections: false  ## if you want number sections at each table header
    theme: united  # many options for theme, this one is my favorite.
    highlight: tango  # specifies the syntax highlighting style
params:
  isSlides: "no"
editor_options: 
  chunk_output_type: console
---

```{r,include=FALSE}
suppressPackageStartupMessages(require(knitr))
library(bluster)
library(decontX)
library(harmony)
library(scCustomize)
library(scater)
library(scran)
library(scDblFinder)
library(scuttle)
library(DropletUtils)
library(celda)
knitr::opts_chunk$set(echo = TRUE, tidy = T)
```

## Overview

In this course we are going to introduce basic analysis for single-cell RNAseq, with a specific focus on the *10X system*. The course is divided into multiple sessions. 

In this third session, we will first evaluate methods to remove the effects of ambient RNA as well as detecting doublets within the data. Following this we will work to integrate a dataset with that we processed in session 2 to create a single dataset for further analysis.

---
## The data

For these sessions we are going to make use of two datasets.

The first set will be from the recent paper [**Enteroendocrine cell lineages that differentially control feeding and gut motility**](https://elifesciences.org/articles/78512).  
This contains scRNA data from either Neurod1 and Neurog3 expressing enteroendocrine cells.


---
## Read in the filtered matrix from CellRanger

The filtered matrix contains droplets considered to be true cell containing droplets. This was performed using the emptyDrops method integrated into CellRanger which we also review ourselves in session 2 using the original implementation in the DropletUtils package.



```{r,fig.width=7,fig.height=4,warning=FALSE}

h5file <- "https://rubioinformatics.s3.amazonaws.com/scRNA_graduate/SRR_NeuroD1/outs/filtered_feature_bc_matrix.h5"
local_h5file <- basename(h5file)
download.file(h5file,local_h5file)

sce.NeuroD1_filtered <- read10xCounts(local_h5file, col.names=TRUE)
sce.NeuroD1_filtered

```

---
## Read in the unfiltered matrix from CellRanger

We also will read in the unfiltered matrix containing all Droplets including non-cell containing droplets which will most likely contain only ambient RNAs.

```{r loadSCE_pres3,include=TRUE,echo=TRUE,eval=TRUE}
h5file <- "https://rubioinformatics.s3.amazonaws.com/scRNA_graduate/SRR_NeuroD1/outs/raw_feature_bc_matrix.h5"
local_h5file <-"NeuroD1_raw_feature_bc_matrix.h5"
download.file(h5file,local_h5file)
sce.NeuroD1_unfiltered <- read10xCounts(local_h5file, col.names=TRUE)
sce.NeuroD1_unfiltered
```

---
## Ambient RNA removal (decontX)

There are many methods to remove ambient RNA using the background proportion of our dataset (lower portion of our knee plot).

First, we will use decontX package to try and remove ambient RNAs.
```{r,fig.width=7,fig.height=4,warning=FALSE}
library(decontX)
```

---
## DecontX

The decontX package is best implemented by providing the filtered and unfiltered datasets, here in singlecellexperiment format.

```{r,include=FALSE,eval=FALSE}
sce.NeuroD1_filtered <- decontX(sce.NeuroD1_filtered, background = sce.NeuroD1_unfiltered)
saveRDS(sce.NeuroD1_filtered,file = "decontx.RDS")
sce.NeuroD1_filtered
```

```{r,echo=FALSE,eval=TRUE}
rdsfile <- "https://rubioinformatics.s3.amazonaws.com/scRNA_graduate/SRR_NeuroD1/outs/decontx.RDS"
local_rdsfile <-"decontx.RDS"
download.file(rdsfile,local_rdsfile)
sce.NeuroD1_filtered <- readRDS(local_rdsfile)
sce.NeuroD1_filtered
```

---
## DecontX

The SingleCellExperiemnt object now contains the **decontXcounts assay slot** containing corrected counts

```{r,echo=FALSE,eval=TRUE}
assays(sce.NeuroD1_filtered)[["decontXcounts"]][1:2,1:4]
```

---
## DecontX

As well as **decontX_contamination** and **decontX_cluster** columns in the colData.

```{r,echo=FALSE,eval=TRUE}
colData(sce.NeuroD1_filtered)
```

---
## DecontX

Also we will have an additional reducedDim **decontX_UMAP**.

```{r,echo=FALSE,eval=TRUE}
reducedDim(sce.NeuroD1_filtered)[1:2,]
```

---
## DecontX

As part of its ambient RNA procedure, decontX has generated clusters and a UMAP projection.

We can review these projections to see the structure of ambient RNA in our data.

```{r,echo=FALSE,eval=TRUE}
umap <- reducedDim(sce.NeuroD1_filtered, "decontX_UMAP")
plotDimReduceCluster(x = sce.NeuroD1_filtered$decontX_clusters,
    dim1 = umap[, 1], dim2 = umap[, 2])
```

---
## DecontX

We can then assess the degree of ambient RNA contamination in each cell using the **decontX_contamination** colData column.

```{r,echo=FALSE,eval=TRUE}
plotDecontXContamination(sce.NeuroD1_filtered)
```

---
## Overlay DecontX

We could also overlay our decontX scores onto the data we created in session2.

```{r,fig.width=7,fig.height=4,warning=FALSE}
sce.NeuroD1_filtered_QCed <- readRDS("/Users/thomascarroll/Github/scRNA-seq2/sce.NeuroD1_filtered_QCed.RDS")
sce.NeuroD1_filtered_QCed$decontX_contamination <- sce.NeuroD1_filtered$decontX_contamination[match(colnames(sce.NeuroD1_filtered_QCed),colnames(sce.NeuroD1_filtered),nomatch = 0)]
```

---
## Overlay DecontX

We can now review whether any of our clusters have a high degree of ambient RNAs.

```{r,fig.width=7,fig.height=4,warning=FALSE}
plotColData(sce.NeuroD1_filtered_QCed,x = "label",y="decontX_contamination")
```

---
## Overlay DecontX

Now we can review the clusters and ambient RNA contamination within a UMAP.

```{r,fig.width=7,fig.height=4,warning=FALSE}
plotUMAP(sce.NeuroD1_filtered_QCed,colour_by ="label")
```

---
## Overlay DecontX

```{r,fig.width=7,fig.height=4,warning=FALSE}
plotUMAP(sce.NeuroD1_filtered_QCed,colour_by ="decontX_contamination")
```

---

## CellBender

An alternative an popular method for removing artefacts from your singlecell data is CellBender.

CellBender uses machine learning to identify features such as ambient RNA and can provide a filtered matrix such as CellRanger for a starting point.

We can run CellBender on our samples with defaults using the example below.

```
cellbender remove-background --input ./rerunSRR_NeuroD1/outs/raw_feature_bc_matrix.h5 --output ./rerunSRR_NeuroD1/outs/cellbender_v0.3.2.h5
```

---

## CellBender

Note CellBender is **much** faster running on a GPU so if we have one available we can use the --cuda flag to speed things up.

```
cellbender remove-background --input ./rerunSRR_NeuroD1/outs/raw_feature_bc_matrix.h5 --output ./rerunSRR_NeuroD1/outs/cellbender_v0.3.2.h5 --cuda
```

---

## CellBender

CellBender outputs a filtered matrix file in H5 format for data import and among other outputs a HTML file summarising important metrics and CSV file of metrics summarised.

[HTML Report](https://rubioinformatics.s3.amazonaws.com/scRNA_graduate/SRR_NeuroD1/outs/cellbender_v0.3.2_report.html)
[Metrics](https://rubioinformatics.s3.amazonaws.com/scRNA_graduate/SRR_NeuroD1/outs/cellbender_v0.3.2_metrics.csv)


---

## CellBender import

We can import the CellBender filtered matrix as before with the CellRanger matrix.

```{r,fig.width=7,fig.height=4}

h5file <- "https://rubioinformatics.s3.amazonaws.com/scRNA_graduate/SRR_NeuroD1/outs/cellbender_v0.3.2_filtered.h5"
local_h5file <- basename(h5file)
download.file(h5file,local_h5file)

sce.NeuroD1_CellBender <- read10xCounts(local_h5file, col.names=TRUE,row.names = "symbol")
sce.NeuroD1_CellBender$Sample <- "Nd1"
class(sce.NeuroD1_CellBender)

```

---

## CellBender import

```{r,fig.width=7,fig.height=4,warning=FALSE}
sce.NeuroD1_CellBender
```


---
## QC CellBender

Now we have an ambient RNA corrected matrix we can reprocess our dataset as before.

First we gather the QC.

```{r,fig.width=7,fig.height=4}
is.mito <- grepl("^MT",rowData(sce.NeuroD1_CellBender)$Symbol)
sce.NeuroD1_CellBender <- addPerCellQCMetrics(sce.NeuroD1_CellBender, 
                                            subsets=list(Mito=is.mito))
p1 <- plotColData(sce.NeuroD1_CellBender,x="sum",y="detected")
p2 <- plotColData(sce.NeuroD1_CellBender,x="sum",y="subsets_Mito_percent")
p3 <- plotColData(sce.NeuroD1_CellBender,x="detected",y="subsets_Mito_percent")
gridExtra::grid.arrange(p1,p2,p3,ncol=3)
```

---
## Filter CellBender

```{r,fig.width=7,fig.height=4,warning=FALSE}
qc.high_lib_size <- colData(sce.NeuroD1_CellBender)$sum > 125000
qc.min_detected <- colData(sce.NeuroD1_CellBender)$detected < 200
qc.mito <- colData(sce.NeuroD1_CellBender)$subsets_Mito_percent > 25
discard <- qc.high_lib_size | qc.mito | qc.min_detected
colData(sce.NeuroD1_CellBender) <- cbind(colData(sce.NeuroD1_CellBender),DataFrame(toDiscard=discard))
sce.NeuroD1_CellBender_QCed <- sce.NeuroD1_CellBender[,sce.NeuroD1_CellBender$toDiscard %in% "FALSE"]
```

---
## Normalise, PCA and projections


```{r,fig.width=7,fig.height=4,warning=FALSE}
set.seed(100)
clust.sce.NeuroD1_CellBender_QCed <- quickCluster(sce.NeuroD1_CellBender_QCed) 
sce.NeuroD1_CellBender_trimmed <- computeSumFactors(sce.NeuroD1_CellBender_QCed, cluster=clust.sce.NeuroD1_CellBender_QCed)
sce.NeuroD1_CellBender_QCed <- logNormCounts(sce.NeuroD1_CellBender_QCed)
dec.NeuroD1_CellBender_QCed <- modelGeneVar(sce.NeuroD1_CellBender_QCed)
top.NeuroD1_CellBender_QCed <- getTopHVGs(dec.NeuroD1_CellBender_QCed, n=3000)
sce.NeuroD1_CellBender_QCed <- fixedPCA(sce.NeuroD1_CellBender_QCed,
                                      subset.row=top.NeuroD1_CellBender_QCed) 
sce.NeuroD1_CellBender_QCed <- runTSNE(sce.NeuroD1_CellBender_QCed,n_dimred=30)
sce.NeuroD1_CellBender_QCed <- runUMAP(sce.NeuroD1_CellBender_QCed,n_dimred=30)
```

---
## Cluster CellBender

```{r,fig.width=7,fig.height=4,warning=FALSE}
library(bluster)
clust.louvain <- clusterCells(sce.NeuroD1_CellBender_QCed, use.dimred="PCA", 
                                BLUSPARAM=NNGraphParam(cluster.fun="louvain",
                                                       cluster.args = list(resolution=0.8)))
clust.default <- clusterCells(sce.NeuroD1_CellBender_QCed, use.dimred="PCA")
colLabels(sce.NeuroD1_CellBender_QCed) <- clust.louvain
colData(sce.NeuroD1_CellBender_QCed)$DefaultLabel <- clust.default
```

---
## Review CellBender

```{r,fig.width=7,fig.height=4,warning=FALSE}
plotUMAP(sce.NeuroD1_CellBender_QCed,colour_by="label")
```

---
## Cell annotation to CellBender

We can then add the known annotation again.
```{r,fig.width=7,fig.height=4,warning=FALSE}
eec_paper_meta <- read.delim("https://rubioinformatics.s3.amazonaws.com/scRNA_graduate/GSE224223_EEC_metadata.csv",sep=";")
nrd1_cells <- as.data.frame(eec_paper_meta[eec_paper_meta$Library == "Nd1",])

nrd1_cells$X <- gsub("_2$","",nrd1_cells$X)

sce.NeuroD1_CellBender_QCed$All_Cell_Types <- nrd1_cells$All_Cell_Types[match(colnames(sce.NeuroD1_CellBender_QCed),nrd1_cells$X,nomatch = NA)]
```

---
## Cell annotation to CellBender

And review this annotation in the UMAP

```{r,fig.width=7,fig.height=4,warning=FALSE}
plotUMAP(sce.NeuroD1_CellBender_QCed,colour_by="All_Cell_Types")
```

---
## Doublet detection and removal

Doublets occur when two cells are within one droplet. This results in a droplet having the average expression of these two cells.

We can remove Doublets from our data using multiple methods. Here we will use scDblFinder


```{r,fig.width=7,fig.height=4,warning=FALSE}
library(scDblFinder)
sce.NeuroD1_CellBender_QCed <- scDblFinder(sce.NeuroD1_CellBender_QCed, clusters=colLabels(sce.NeuroD1_CellBender_QCed))
```

---
## Doublet detections and removal

We can then review to see which clusters contained Doublets.
```{r,fig.width=7,fig.height=4,warning=FALSE}
plotColData(sce.NeuroD1_CellBender_QCed,x = "label",y="scDblFinder.score")
```

---
## Doublet detections and removal

We can can also assess the relationship between doublets and other metrics.

```{r,fig.width=7,fig.height=4,warning=FALSE}
p1 <- plotColData(sce.NeuroD1_CellBender_QCed,x = "detected",y="scDblFinder.score")
p2 <- plotColData(sce.NeuroD1_CellBender_QCed,x = "sum",y="scDblFinder.score")
gridExtra::grid.arrange(p1,p2,ncol=2)
```

---
## Doublet detections and removal

And review doublets in our umaps

```{r,fig.width=7,fig.height=4,warning=FALSE}
p1 <- plotUMAP(sce.NeuroD1_CellBender_QCed,colour_by="label")
p2 <- plotUMAP(sce.NeuroD1_CellBender_QCed,colour_by="scDblFinder.score")
gridExtra::grid.arrange(p1,p2,ncol=2)
```

---
## Doublet detections and removal

We can then filter out doublets from our data.

```{r,fig.width=7,fig.height=4,warning=FALSE}
sce.NeuroD1_CellBender_QCDbled <- sce.NeuroD1_CellBender_QCed[sce.NeuroD1_CellBender_QCed$scDblFinder.class != "doublet"]
sce.NeuroD1_CellBender_QCDbled
```

---
## Merging 2 Datasets

Now we have processed our single dataset we can integrate with our second dataset.

I have already processed the Ngn3 dataset in the same way.

```{r,include=FALSE}


rdsfile <- "https://rubioinformatics.s3.amazonaws.com/scRNA_graduate/SRR_Ngn3/outs/sce.Ngn3_CellBender_QCDbled.RDS"
local_rdsfile <-"sce.Ngn3_CellBender_QCDbled.RDS"
download.file(rdsfile,local_rdsfile)
sce.Ngn3_CellBender_QCDbled <- readRDS(local_rdsfile)
sce.Ngn3_CellBender_QCDbled$Sample <- "Ngn3"
unlink(local_rdsfile)

rdsfile <- "https://rubioinformatics.s3.amazonaws.com/scRNA_graduate/SRR_Ngn3/outs/dec.Ngn3_CellBender_QCed.RDS"
local_rdsfile <-"dec.Ngn3_CellBender_QCed.RDS"
download.file(rdsfile,local_rdsfile)
dec.Ngn3_CellBender_QCed <- readRDS(local_rdsfile)
unlink(local_rdsfile)

```

```{r,fig.width=7,fig.height=4,warning=FALSE}
plotUMAP(sce.Ngn3_CellBender_QCDbled,colour_by="All_Cell_Types")
```

---
## Merging 2 Datasets

To merge the two datasets we first need to get objects in sync.
Here we make sure the two datasets have the same genes within them

```{r,fig.width=7,fig.height=4,warning=FALSE}
uni <- intersect(rownames(sce.NeuroD1_CellBender_QCDbled),
rownames(sce.Ngn3_CellBender_QCDbled))

sce.NeuroD1 <- sce.NeuroD1_CellBender_QCDbled[uni,]
sce.Ngn3 <- sce.Ngn3_CellBender_QCDbled[uni,]

```

---
## Merging 2 Datasets

We also tidy up the mcols as well.

```{r,fig.width=7,fig.height=4,warning=FALSE}

mcols(sce.NeuroD1) <- mcols(sce.NeuroD1)[,-4]
mcols(sce.Ngn3) <- mcols(sce.Ngn3)[,-4]

```

---
## Merging 2 Datasets

We can combine the two datasets with **cbind**

```{r,fig.width=7,fig.height=4,warning=FALSE}
sce.all <- cbind(sce.NeuroD1,sce.Ngn3)
```

---
## Merging 2 Datasets

We need to also gather a common set of variable genes.

```{r,fig.width=7,fig.height=4,warning=FALSE}
dec.NeuroD1 <- dec.NeuroD1_CellBender_QCed[uni,]
dec.Ngn3 <- dec.Ngn3_CellBender_QCed[uni,]
combined.dec <- combineVar(dec.NeuroD1, dec.Ngn3)
chosen.hvgs <- combined.dec$bio > 0
```

---
## Running PCA and TSNE

```{r,fig.width=7,fig.height=4,warning=FALSE}
library(scater)
set.seed(0010101010)
sce.all <- runPCA(sce.all, subset_row=chosen.hvgs)
sce.all <- runTSNE(sce.all, dimred="PCA")
```

---
## Review TSNE

```{r fig.height=4, warning=FALSE, r,fig.width=7}
plotTSNE(sce.all, colour_by="Sample")
```

---
## Review TSNE

```{r,fig.width=7,fig.height=4,warning=FALSE}
plotTSNE(sce.all, colour_by="Sample")+facet_wrap(~colour_by)
```

---
## Review TSNE

```{r,fig.width=7,fig.height=4,warning=FALSE}
plotTSNE(sce.all, colour_by="All_Cell_Types",shape_by="Sample")+facet_wrap(~shape_by)
```

---
## Review TSNE

```{r,fig.width=7,fig.height=4,warning=FALSE}
plotTSNE(sce.all, colour_by="Sample",shape_by="All_Cell_Types")+facet_wrap(~shape_by)
```

---
## MNN batch correction.

So far we have applied no batch correction to our data.

Here we will apply the fastMNN batch correction from the **batchelor** package

```{r,fig.width=7,fig.height=4,warning=FALSE}
library(batchelor)
set.seed(1000101001)
sce.all.mnn <- fastMNN(sce.all,batch = sce.all$Sample,d=50, k=20, subset.row=chosen.hvgs)

```

---
## Add Celltype annotation again.

```{r,fig.width=7,fig.height=4,warning=FALSE}
eec_paper_meta <- read.delim("https://rubioinformatics.s3.amazonaws.com/scRNA_graduate/GSE224223_EEC_metadata.csv",sep=";")
nrd1_cells <- as.data.frame(eec_paper_meta)

nrd1_cells$X <- gsub("_2$|_1$","",nrd1_cells$X)

sce.all.mnn$All_Cell_Types <- nrd1_cells$All_Cell_Types[match(colnames(sce.all.mnn),nrd1_cells$X,nomatch = NA)]
```

---
##Clustering 

```{r,fig.width=7,fig.height=4,warning=FALSE}
library(bluster)
clust.louvain <- clusterCells(sce.all.mnn, use.dimred="corrected", 
                                BLUSPARAM=NNGraphParam(cluster.fun="louvain",
                                                       cluster.args = list(resolution=0.5)))
colData(sce.all.mnn)$MNNLabel <- clust.louvain
```

---
## TSNE and UMAP.

We can then use the corrected PCA from fastMNN to make our corrected TSNE and UMAPs

```{r,fig.width=7,fig.height=4,warning=FALSE}
sce.all.mnn <- runTSNE(sce.all.mnn, dimred="corrected",name="MNN.TSNE")
sce.all.mnn <- runUMAP(sce.all.mnn, dimred="corrected",name="MNN.UMAP")
```

---
## Review TSNE and UMAP

```{r,fig.width=7,fig.height=4,warning=FALSE}
plotUMAP(sce.all.mnn,
         colour_by="All_Cell_Types",
         shape_by="batch",dimred="MNN.UMAP")+facet_wrap(~shape_by)
```

---
## Review TSNE and UMAP

```{r,fig.width=7,fig.height=4,warning=FALSE}
plotUMAP(sce.all.mnn,
         colour_by="MNNLabel",
         shape_by="batch",dimred="MNN.UMAP")+facet_wrap(~shape_by)
```

---
## Review TSNE and UMAP

```{r,fig.width=7,fig.height=4,warning=FALSE}
plotUMAP(sce.all.mnn,
         colour_by="batch",
         shape_by="All_Cell_Types",dimred="MNN.UMAP")+facet_wrap(~shape_by)
```

---
## Harmony correction

Another apporach to batch correction is implemented in harmony.

```{r,fig.width=7,fig.height=4,warning=FALSE}
library(harmony)
sce.all.harmony <- RunHarmony(sce.all,group.by.vars="Sample")
```

---
## Add cell annotation.

```{r,fig.width=7,fig.height=4,warning=FALSE}
sce.all.harmony$All_Cell_Types <- nrd1_cells$All_Cell_Types[match(colnames(sce.all.harmony),nrd1_cells$X,nomatch = NA)]
```

---
##Clustering 

```{r,fig.width=7,fig.height=4,warning=FALSE}
library(bluster)
clust.louvain <- clusterCells(sce.all.harmony, use.dimred="HARMONY", 
                                BLUSPARAM=NNGraphParam(cluster.fun="louvain",
                                                       cluster.args = list(resolution=0.5)))
colData(sce.all.harmony)$HARMONYLabel <- clust.louvain
```

---
## TSNE and UMAP.

We can then use the corrected PCA from Harmony to make our corrected TSNE and UMAPs.

```{r,fig.width=7,fig.height=4,warning=FALSE}
plotReducedDim(sce.all.harmony,dimred = "HARMONY",colour_by = "subsets_Mito_percent")
```

---
## TSNE and UMAP.

We can then use the corrected PCA from Harmony to make our corrected TSNE and UMAPs.

```{r,fig.width=7,fig.height=4,warning=FALSE}

sce.all.harmony <- runUMAP(sce.all.harmony, dimred="HARMONY",name="HARMONY.UMAP")

plotUMAP(sce.all.harmony,colour_by="HARMONYLabel",dimred = "HARMONY.UMAP",
         shape_by="Sample")+facet_wrap(~shape_by)
```

---
## TSNE and UMAP.

```{r,fig.width=7,fig.height=4,warning=FALSE}

plotUMAP(sce.all.harmony,colour_by="All_Cell_Types",
         ,dimred = "HARMONY.UMAP",
         shape_by="Sample")+facet_wrap(~shape_by)
```

---
## Seurat

We can also use our CellBender output in Seurat.

At the moment however we have to import using the **scCustomize** package.
```{r,fig.width=7,fig.height=4,warning=FALSE}
library(Seurat)
library(scCustomize)
h5file <- "https://rubioinformatics.s3.amazonaws.com/scRNA_graduate/SRR_NeuroD1/outs/cellbender_v0.3.2_filtered.h5"
local_h5file <- basename(h5file)
download.file(h5file,local_h5file)
Neurod1.mat <- Read_CellBender_h5_Mat(file_name = local_h5file)
Neurod1.obj <- CreateSeuratObject(Neurod1.mat, project = "Nd1")
```

---
## Seurat

We then process as before to get QC and filter.

```{r,fig.width=7,fig.height=4,warning=FALSE}
mito.genes <- grep("^MT", rownames(Neurod1.obj), value = T)

percent.mt <- PercentageFeatureSet(Neurod1.obj, features = mito.genes)
Neurod1.obj <- AddMetaData(Neurod1.obj,metadata = percent.mt,col.name = "percent.mt")
Neurod1.obj.filt <- subset(Neurod1.obj, subset = `nCount_RNA` < 125000 & percent.mt < 25 & nFeature_RNA > 200)



```

---
## Seurat

And then normalise, run PCA and generate UMAPs.


```{r,fig.width=7,fig.height=4,warning=FALSE}
Neurod1.obj.filt <- NormalizeData(Neurod1.obj.filt)
Neurod1.obj.filt <- FindVariableFeatures(Neurod1.obj.filt, selection.method = "vst", nfeatures = 3000)
all.genes <- rownames(Neurod1.obj.filt)
Neurod1.obj.filt <- ScaleData(Neurod1.obj.filt, features = all.genes)
Neurod1.obj.filt <- RunPCA(Neurod1.obj.filt, features = VariableFeatures(object = Neurod1.obj))
Neurod1.obj.filt <- RunUMAP(Neurod1.obj.filt, dims = 1:30)
```

---
## Seurat

And finally define our clusters

```{r,fig.width=7,fig.height=4,warning=FALSE}
Neurod1.obj.filt <- FindNeighbors(Neurod1.obj.filt, dims = 1:30)
Neurod1.obj.filt <- FindClusters(Neurod1.obj.filt, resolution = 0.7)
```

---
## Seurat

Now we can review our UMAP

```{r,fig.width=7,fig.height=4,warning=FALSE}
DimPlot(Neurod1.obj.filt, reduction = "umap")
```

---
## Ngn3 Seurat


```{r,include=FALSE}

options(timeout = 60*10000)
rdsfile <- "https://rubioinformatics.s3.amazonaws.com/scRNA_graduate/SRR_Ngn3/outs/Ngn3.obj.filt.RDS"
local_rdsfile <-"Ngn3.obj.filt.RDS"
download.file(rdsfile,local_rdsfile)
Ngn3.obj.filt <- readRDS(local_rdsfile)
unlink(local_rdsfile)


```

```{r,fig.width=7,fig.height=4,warning=FALSE}
DimPlot(Ngn3.obj.filt, reduction = "umap")
```

---
## Seurat- 2 datasets

We can combine two datasets using the merge function in Seurat.

```{r,fig.width=7,fig.height=4,warning=FALSE}
All.obj <- merge(Neurod1.obj.filt, y = Ngn3.obj.filt, add.cell.ids = c("Nd1", "Ngn3"), project = "All",merge.data = TRUE)
All.obj
```

---
## Seurat- 2 datasets

Once merged we can run a standard processing.

```{r,fig.width=7,fig.height=4,warning=FALSE}
All.obj <- NormalizeData(All.obj)
All.obj <- FindVariableFeatures(All.obj)
All.obj <- ScaleData(All.obj)
All.obj <- RunPCA(All.obj)
All.obj <- FindNeighbors(All.obj, dims = 1:30, reduction = "pca")
All.obj <- FindClusters(All.obj, resolution = 2, cluster.name = "unintegrated_clusters")
All.obj <- RunUMAP(All.obj, dims = 1:30, reduction = "pca", reduction.name = "umap.unintegrated")
```

---
## Seurat- Review merging

We can review any batch effects using our umap.
```{r,fig.width=7,fig.height=4,warning=FALSE}
DimPlot(All.obj, reduction = "umap.unintegrated",group.by = "orig.ident")
```

---
## Seurat- Integration

We can integrate and batch correct our datasets using the **IntegrateLayers** layers function. 

This allows for many different integration methods. Here we will use Harmony again.

```{r,fig.width=7,fig.height=4,warning=FALSE}
All.obj <- IntegrateLayers(
  object = All.obj, method = HarmonyIntegration,
  orig.reduction = "pca", new.reduction = "integrated.harmony",
  verbose = TRUE
)
```

---
## Seurat- Downstream of integration

Now we remake our clusters using the harmony integrated data.

```{r,fig.width=7,fig.height=4,warning=FALSE}
All.obj[["RNA"]] <- JoinLayers(All.obj[["RNA"]])
All.obj <- FindNeighbors(All.obj, reduction = "integrated.harmony", dims = 1:30)
All.obj <- FindClusters(All.obj, resolution = 0.5, cluster.name = "harmony_clusters")
```

---
## Seurat- Downstream of integration

Lastly we can create our UMAP from harmony integrated data.


```{r,fig.width=7,fig.height=4,warning=FALSE}
All.obj <- RunUMAP(All.obj, reduction = "integrated.harmony", dims = 1:30, reduction.name = "umap.harmony")
```

---
## Seurat- Review integration


```{r,fig.width=7,fig.height=4,warning=FALSE}
DimPlot(
  All.obj,
  reduction = "umap.harmony",
  group.by = "harmony_clusters",
  combine = FALSE, label.size = 2
)

```

---
## Seurat- Review integration

```{r,fig.width=7,fig.height=4,warning=FALSE}
DimPlot(
  All.obj,
  reduction = "umap.harmony",
  group.by = "orig.ident",
  combine = FALSE, label.size = 2
)
```

---
## Markers within/between batches

Batch correction is often performed on the PCs (MNN and Harmony) and so is used for UMAP and clustering.

```{r,fig.width=7,fig.height=4,warning=FALSE}
plotUMAP(sce.all.mnn,colour_by="MNNLabel",dimred = "MNN.UMAP")
```

---
## Markers within/between batches

MNN correction does return a batch corrected matrix (**reconstructed** assay) but this is not recommended for differential expression or marker gene detection.

Instead it is recommended we use the log normalised data and account for batches as part of our marker gene detection.

First then we add MNN clusters detected back to our uncorrected SingleCellExperiment object.

```{r,fig.width=7,fig.height=4,warning=FALSE}
sce.all$MNNLabel <- sce.all.mnn$MNNLabel
sce.all$batch <- sce.all.mnn$batch
```

---
## Markers within/between batches

We now run the findMarkers function adding an additional parameter of **block** to identify markers of MNN identified clusters while accounting for batch/sample differences.

```{r,fig.width=7,fig.height=4,warning=FALSE}
m.out <- findMarkers(sce.all, sce.all$MNNLabel, block=sce.all$batch,
    direction="up", lfc=1)

```

---
## Markers within/between batches

We can then review these as before

```{r,fig.width=7,fig.height=4,warning=FALSE}
m.out[["1"]][,c("summary.logFC", "Top", "p.value", "FDR")]
```

---
## Markers within/between batches

And visualise these markers in clusters while splitting by batch/sample.

```{r,fig.width=7,fig.height=4,warning=FALSE}
plotExpression(sce.all,features = c("Chgb","Reg4"),x = "MNNLabel",colour_by = "batch")+facet_wrap(Feature~colour_by)
```


---
## Markers within/between batches

We can also visualise them using the MNN **reconstructed** matrix.

```{r,fig.width=7,fig.height=4,warning=FALSE}
plotExpression(sce.all.mnn,features = c("Chgb","Reg4"),x = "MNNLabel",exprs_values = "reconstructed",colour_by = "batch")+facet_wrap(Feature~colour_by)
```




---
## Markers within/between batches

Finding markers within a cluster across samples/condition while accounting for batch is not possible given that batch is the same as sample/condition.

We can however combine cluster/sample labels and make a comparison across conditions.

```{r,fig.width=7,fig.height=4,warning=FALSE}
sce.all$Condition_Cluster <- paste(sce.all$Sample,sce.all$MNNLabel,sep="_")
Nd1_vs_Ngn3_Cluster9 <- scoreMarkers(sce.all,sce.all$Condition_Cluster,pairings=c("Nd1_9","Ngn3_9"))
```

---
## Markers within/between batches

Reviewing this we see that we are now simply capturing difference between samples.

```{r,fig.width=7,fig.height=4,warning=FALSE}
Nd1_vs_Ngn3_Cluster9_Res <- Nd1_vs_Ngn3_Cluster9$Nd1_9
Nd1_vs_Ngn3_Cluster9_Res <- Nd1_vs_Ngn3_Cluster9_Res[order(Nd1_vs_Ngn3_Cluster9_Res$mean.AUC, decreasing=TRUE),]
plotExpression(sce.all,
               features = c("Xist"),
               x = "MNNLabel",colour_by = "batch")+facet_wrap(Feature~colour_by)

```


---
## Seurat

Seurat also offers a mechanism to block with in batches for identifying cluster markers while accounting for samples.

```{r,fig.width=7,fig.height=4,warning=FALSE}
Idents(All.obj) <- "harmony_clusters"
harmony.markers <- FindConservedMarkers(All.obj, ident.1 = 1, grouping.var = "orig.ident", verbose = FALSE)
VlnPlot(All.obj,features = "Slc38a11",split.by = "orig.ident")
```

---
## Seurat

However we have the same issue for when comparing across conditions.

```{r,fig.width=7,fig.height=4,warning=FALSE}
All.obj[["Condition_Cluster"]] <- paste(All.obj$orig.ident,All.obj$harmony_clusters,sep="_")
Idents(All.obj) <- "Condition_Cluster"
res <- FindMarkers(All.obj, ident.1 = "Nd1_1", ident.2="Ngn3_1", verbose = FALSE)
```

---
## scTransform.

scTransform is an alternative workflow for normalising and scaling data which was put forward by Seurat authors.

It replaces normalised counts with residuals from fitting a model per gene while also allowing us to regress out features from our data. 

```{r,fig.width=7,fig.height=4,warning=FALSE}
Neurod1.obj.scTransform <- subset(Neurod1.obj, subset = `nCount_RNA` < 125000 & percent.mt < 25 & nFeature_RNA > 200)
Neurod1.obj.scTransform <- SCTransform(Neurod1.obj.scTransform,vars.to.regress = "percent.mt")
```

---
## scTransform.

An additional SCT slot is created containing these residuals for further analysis.


```{r,fig.width=7,fig.height=4,warning=FALSE}
Neurod1.obj.scTransform
```

---
## scTransform.

Following this transformation we can procede as normal with analysis.

```{r,fig.width=7,fig.height=4,warning=FALSE}
Neurod1.obj.scTransform <- RunPCA(Neurod1.obj.scTransform)
Neurod1.obj.scTransform <- RunUMAP(Neurod1.obj.scTransform, dims = 1:30)
Neurod1.obj.scTransform <- FindNeighbors(Neurod1.obj.scTransform, dims = 1:30)
Neurod1.obj.scTransform <- FindClusters(Neurod1.obj.scTransform, resolution = 0.7)

```

---
## scTransform.

```{r,echo=FALSE,eval=TRUE}
rdsfile <- "https://rubioinformatics.s3.amazonaws.com/scRNA_graduate/SRR_Ngn3/outs/Ngn3.obj.scTranform.RDS"
local_rdsfile <-"Ngn3.obj.scTranform.RDS"
download.file(rdsfile,local_rdsfile)
Ngn3.obj.scTransform <- readRDS(local_rdsfile)
Ngn3.obj.scTransform
```

We can also use scTransform with Batch correction. First we must prepare and merge our data.

```{r,fig.width=7,fig.height=4,warning=FALSE}
All.obj.sct <- merge(Neurod1.obj.scTransform, 
                 y = Ngn3.obj.scTransform, add.cell.ids = c("Nd1", "Ngn3"), project = "All",merge.data = TRUE)
All.obj.sct <- SCTransform(All.obj.sct,
                           vars.to.regress = "percent.mt")
```

---
## scTransform.

Following this we an integrate our data using the SCT normalised values. We simply specify "SCT" to the normalisation.method parameter.


```{r,fig.width=7,fig.height=4,warning=FALSE}
All.obj.sct <- RunPCA(All.obj.sct)
All.obj.sct <- RunUMAP(All.obj.sct, dims = 1:30)
All.obj.sct <- IntegrateLayers(object = All.obj.sct, 
                        method = HarmonyIntegration, 
                        normalization.method = "SCT", 
                        verbose = F)

```

---
## scTransform.

Once transformed we can cluster, create our UMAP and visualise.

```{r,fig.width=7,fig.height=4,warning=FALSE}
All.obj.sct <- FindNeighbors(All.obj.sct, reduction = "harmony", dims = 1:30)
All.obj.sct <- FindClusters(All.obj.sct, resolution = 0.3)
All.obj.sct <- RunUMAP(All.obj.sct, dims = 1:30, reduction = "harmony")

DimPlot(All.obj.sct, reduction = "umap", group.by = c("orig.ident","SCT_snn_res.0.3"))

```

---
## scTransform.

For downstream marker analysis it is recommended we normalise our data across batchs using the **PrepSCTFindMarkers** function.

```{r,fig.width=7,fig.height=4,warning=FALSE}
All.obj.sct <- PrepSCTFindMarkers(All.obj.sct)
```

---
## scTransform.

Following this we can run FindMarkers on our data to identify markers across samples.

```{r,fig.width=7,fig.height=4,warning=FALSE}
harmonySCT.markers <- FindMarkers(All.obj.sct, ident.1 = 3, verbose = FALSE)
VlnPlot(All.obj.sct,features = "Tph1",split.by = "orig.ident")

```
